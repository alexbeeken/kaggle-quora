{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Questions Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the csv\n",
    "\n",
    "Import CSV and store selected rows in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "questions = []\n",
    "\n",
    "with open('q_quora_100.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        questions.append(row[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first row of the csv, the column keys. For double checking that the columns are the ones we want to easily refer back to see which columns are which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names\n",
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n"
     ]
    }
   ],
   "source": [
    "keys = questions[0]\n",
    "print 'column names'\n",
    "print keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify any columns that have the wrong number of columns. This was found because commas were used in some questions which messed up the csv parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in questions:\n",
    "    if len(row) != 6:\n",
    "        print 'WARNING: A COLUMN NEEDS FIXING' + str(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert python list to numpy array and delete the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2'\n",
      " 'What is the step by step guide to invest in share market in india?'\n",
      " 'What is the step by step guide to invest in share market?' '0']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "questions = np.array(questions)\n",
    "questions = np.delete(questions, 0, 0)\n",
    "print questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "First take a random entry in the dataset to get a feel for the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr><tr><td>46</td><td>93</td><td>94</td><td>How did Darth Vader fought Darth Maul in Star Wars Legends?</td><td>Does Quora have a character limit for profile descriptions?</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "size = len(questions)\n",
    "random_index = random.randrange(size)\n",
    "random_question = questions[random_index]\n",
    "\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in random_question)) for row in random_question)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a count of how many duplicates and what percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates: 36 percentage: 0.349514563107%\n",
      "not duplicates: 67 percentage: 0.650485436893%\n"
     ]
    }
   ],
   "source": [
    "duplicates = 0\n",
    "not_duplicates = 0\n",
    "total = len(questions)\n",
    "\n",
    "for row in questions:\n",
    "    if row[5] == '0':\n",
    "        not_duplicates += 1\n",
    "    else:\n",
    "        duplicates += 1\n",
    "\n",
    "print 'duplicates: ' + str(duplicates) + ' percentage: ' + str((float(duplicates) / float(total))) + '%'\n",
    "print 'not duplicates: ' + str(not_duplicates) + ' percentage: ' + str(float(not_duplicates) / float(total)) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "### Munging\n",
    "\n",
    "Downcase and then split the sentence into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'], ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market?']], ['1', ['what', 'is', 'the', 'story', 'of', 'kohinoor', '(koh-i-noor)', 'diamond?'], ['what', 'would', 'happen', 'if', 'the', 'indian', 'government', 'stole', 'the', 'kohinoor', '(koh-i-noor)', 'diamond', 'back?']], ['2', ['how', 'can', 'i', 'increase', 'the', 'speed', 'of', 'my', 'internet', 'connection', 'while', 'using', 'a', 'vpn?'], ['how', 'can', 'internet', 'speed', 'be', 'increased', 'by', 'hacking', 'through', 'dns?']], ['3', ['why', 'am', 'i', 'mentally', 'very', 'lonely?', 'how', 'can', 'i', 'solve', 'it?'], ['find', 'the', 'remainder', 'when', '[math]23^{24}[/math]', 'is', 'divided', 'by', '24,23?']]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "processing = []\n",
    "\n",
    "\n",
    "for data in questions:\n",
    "    pairId = data[0]\n",
    "    sentence1 = data[3].lower()\n",
    "    sentence2 = data[4].lower()\n",
    "    matches = reg.match(data[3])\n",
    "    tokens1 = sentence1.split(' ')\n",
    "    tokens2 = sentence2.split(' ')\n",
    "    processing.append([\n",
    "        pairId,\n",
    "        tokens1,\n",
    "        tokens2\n",
    "    ])\n",
    "    \n",
    "print(processing[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all stopwords and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', ['step', 'step', 'guide', 'invest', 'share', 'market', 'india'], ['step', 'step', 'guide', 'invest', 'share', 'market']], ['1', ['story', 'kohinoor', 'kohinoor', 'diamond'], ['would', 'happen', 'indian', 'government', 'stole', 'kohinoor', 'kohinoor', 'diamond', 'back']], ['2', ['increase', 'speed', 'internet', 'connection', 'using', 'vpn'], ['internet', 'speed', 'increased', 'hacking', 'dns']], ['3', ['mentally', 'lonely', 'solve', 'it'], ['find', 'remainder', 'mathmath', 'divided']], ['4', ['one', 'dissolve', 'water', 'quikly', 'sugar', 'salt', 'methane', 'carbon', 'di', 'oxide'], ['fish', 'would', 'survive', 'salt', 'water']]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexbeeken/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "munged = []\n",
    "\n",
    "def remove_stop(sentence, words=stopwords.words('english')):\n",
    "    remove_these = []\n",
    "    for i in range(0, len(sentence) - 1):\n",
    "        word = sentence[i]\n",
    "        if word in words:\n",
    "            remove_these.append(i)\n",
    "    output = []\n",
    "    for i in range(0, len(sentence)):\n",
    "        if i not in remove_these:\n",
    "            punctuationless = remove_punctuation(sentence[i])\n",
    "            if len(punctuationless) > 0:\n",
    "                output.append(punctuationless)\n",
    "    return output\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    return re.sub('[^a-zA-Z]', '', word)\n",
    "\n",
    "for data in processing:\n",
    "    pairId = data[0]\n",
    "    sentence1 = data[1]\n",
    "    sentence2 = data[2]\n",
    "    out1 = remove_stop(sentence1)\n",
    "    out2 = remove_stop(sentence2)\n",
    "        \n",
    "    munged.append([\n",
    "        pairId,\n",
    "        out1,\n",
    "        out2\n",
    "    ])\n",
    "    \n",
    "print munged[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Order words by popularity\n",
    "\n",
    "We'll create a list of all words used in the corpus. Then we'll count the occurences of each word and order it by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'step', 'guide', 'invest', 'share', 'market', 'india', 'step', 'step', 'guide', 'invest', 'share', 'market', 'story', 'kohinoor', 'kohinoor', 'diamond', 'would', 'happen', 'indian']\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for row in munged:\n",
    "    for word in row[1]:\n",
    "        all_tokens.append(word)\n",
    "    for word in row[2]:\n",
    "        all_tokens.append(word)\n",
    "\n",
    "print all_tokens[0:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
